{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 10 MNIST and softmax\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "    \n",
    "# parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " # dataset loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init model done\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 32, bias =True)\n",
    "        self.fc2 = nn.Linear(32, 32, bias =True)\n",
    "        self.fc3 = nn.Linear(32, 10, bias =True)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(32)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn1(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(\"init model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "model = Net().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Train function and Test function to validate.\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.view(-1,28 * 28).to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = (criterion(output,target))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(output.shape,target.shape)\n",
    "    print(\"epoch : \", epoch)\n",
    "    print(\"training loss : \",loss.item())\n",
    "        \n",
    "    return data,target,output\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.view(-1,28 * 28).to(device), target.to(device)\n",
    "            output = model(data)            \n",
    "            test_loss += (criterion(output, target)).item()\n",
    "    test_loss /= len(test_loader.dataset)/(batch_size)\n",
    "    print(\"test loss : \",test_loss)\n",
    "    return (data, target ,output)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "epoch :  1\n",
      "training loss :  2.4162983894348145\n",
      "epoch :  2\n",
      "training loss :  2.3375144004821777\n",
      "epoch :  3\n",
      "training loss :  2.397766590118408\n",
      "epoch :  4\n",
      "training loss :  2.375211000442505\n",
      "epoch :  5\n",
      "training loss :  2.383662223815918\n",
      "epoch :  6\n",
      "training loss :  2.3326337337493896\n",
      "epoch :  7\n",
      "training loss :  2.3297290802001953\n",
      "epoch :  8\n",
      "training loss :  2.354098081588745\n",
      "epoch :  9\n",
      "training loss :  2.2777340412139893\n",
      "epoch :  10\n",
      "training loss :  2.3781213760375977\n",
      "test loss :  2.47136481552124\n"
     ]
    }
   ],
   "source": [
    "# Train and Test the model and save it.\n",
    "print(\"training\")\n",
    "for epoch in range(1, training_epochs+1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "DATA, TARGET, OUTPUT = test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0), tensor([-0.4924, -0.1519, -0.1132,  0.4359, -0.8443, -0.1157,  0.6434, -0.2933,\n",
      "         0.5668, -0.9996]))\n",
      "(tensor(6), tensor([ 0.1797,  0.1022, -0.0864,  0.4608, -0.4559,  0.1060,  0.4205, -0.4455,\n",
      "         0.0742, -0.6775]))\n",
      "(tensor(2), tensor([-0.1841,  0.6403,  1.3885,  0.1246, -1.1655,  0.0736,  0.3090, -0.9560,\n",
      "        -0.3105, -0.9588]))\n",
      "(tensor(1), tensor([-0.0498,  0.2157,  0.1627,  0.5169, -0.4822,  0.1588,  0.2144, -0.3291,\n",
      "         0.1007, -0.4106]))\n",
      "(tensor(1), tensor([-0.1003,  0.3250,  0.2894,  0.4009, -0.5822,  0.1804,  0.1346, -0.3168,\n",
      "         0.1032, -0.2565]))\n",
      "(tensor(7), tensor([-0.1031,  0.3368, -0.0236,  0.3962, -0.8828,  0.3711,  0.9947, -0.3711,\n",
      "         0.4466, -0.5609]))\n",
      "(tensor(7), tensor([ 0.0988,  0.3227,  0.0365,  0.7360, -0.9248,  0.2196,  0.6376, -0.5244,\n",
      "         0.4530, -0.7183]))\n",
      "(tensor(8), tensor([-0.2513,  0.3625,  0.2211,  0.2090, -0.8944,  0.1603,  0.3615, -0.5286,\n",
      "         0.2263, -0.3525]))\n",
      "(tensor(4), tensor([ 0.0486,  0.5827,  0.0714,  0.3567, -1.2000,  0.1331,  0.4759, -0.7152,\n",
      "         0.2382, -0.6165]))\n",
      "(tensor(6), tensor([-0.3174,  0.7835,  0.4670, -0.2565, -1.1662,  0.4261,  0.0476, -0.2573,\n",
      "        -0.2552, -0.5399]))\n",
      "(tensor(0), tensor([-0.4929,  0.1032, -0.1454,  0.4561, -0.8674, -0.0590,  0.1669, -0.0027,\n",
      "         0.5310, -0.8264]))\n",
      "(tensor(7), tensor([-0.1123,  0.4893, -0.1545,  0.2762, -0.9422,  0.3615,  1.0922, -0.3322,\n",
      "         0.6002, -0.4258]))\n",
      "(tensor(0), tensor([-0.5081, -0.3983,  0.5938,  0.0677, -0.4741, -0.2415,  0.0714, -0.3984,\n",
      "        -0.0733, -0.8382]))\n",
      "(tensor(3), tensor([-0.1480,  0.2573,  0.3172,  0.6153, -0.6939,  0.0893,  0.0970, -0.3844,\n",
      "         0.3175, -0.8912]))\n",
      "(tensor(6), tensor([-0.2505,  0.5774, -0.0201, -0.5018, -1.0414,  0.0942,  0.0729, -0.4491,\n",
      "        -0.2000, -0.3996]))\n",
      "(tensor(8), tensor([-0.0532,  0.4663,  0.0600, -0.0042, -0.7955,  0.1518,  0.3085,  0.0398,\n",
      "         0.1137, -0.6889]))\n",
      "(tensor(7), tensor([-0.0802,  0.1137, -0.0152,  0.3546, -0.8386,  0.2586,  0.6408, -0.4765,\n",
      "         0.5432, -0.7209]))\n",
      "(tensor(1), tensor([-0.1967,  0.5149,  0.3010,  0.3679, -0.7834,  0.1389,  0.2387, -0.4432,\n",
      "         0.1463, -0.3367]))\n",
      "(tensor(5), tensor([-0.6376,  0.1544,  0.4470, -0.2449, -0.5771, -0.3700,  0.0338, -0.4879,\n",
      "        -0.0524, -0.4869]))\n",
      "(tensor(2), tensor([-0.2189,  0.4854,  0.1051,  0.0561, -0.6492,  0.2888,  0.6974, -0.3971,\n",
      "         0.1438, -0.3910]))\n",
      "(tensor(4), tensor([ 0.0768,  0.3083,  0.2629,  0.2389, -0.7633,  0.1645,  0.2511, -0.5561,\n",
      "         0.1327, -0.6430]))\n",
      "(tensor(9), tensor([-0.0209,  0.2004, -0.1381,  0.8086, -0.8055,  0.2487,  1.3962, -0.5364,\n",
      "         0.0255, -0.5073]))\n",
      "(tensor(4), tensor([ 0.0134,  0.1117,  0.0512,  0.3036, -0.2475,  0.2356,  0.4816, -0.3034,\n",
      "        -0.0927, -0.3155]))\n",
      "(tensor(3), tensor([ 0.0440,  0.1582,  0.6589,  0.3132, -0.5202, -0.1058,  0.0528, -0.5360,\n",
      "        -0.0444, -0.5589]))\n",
      "(tensor(6), tensor([ 0.0391,  0.2479, -0.1571,  0.2146, -0.3665,  0.0043,  0.3229, -0.3856,\n",
      "        -0.2500, -0.1954]))\n",
      "(tensor(4), tensor([-0.0963,  0.2596, -0.2809,  0.8350, -0.5896,  0.2473,  0.8127, -0.2818,\n",
      "         0.0870, -0.0187]))\n",
      "(tensor(1), tensor([-0.0130,  0.2593,  0.1176,  0.4963, -0.4582,  0.0398, -0.1546, -0.2434,\n",
      "         0.1897, -0.4165]))\n",
      "(tensor(7), tensor([ 0.0982,  0.4851, -0.2702,  0.2256, -0.9030,  0.3257,  0.9324, -0.1590,\n",
      "         0.3207, -0.6148]))\n",
      "(tensor(2), tensor([-0.5088,  0.3930,  0.5107, -0.1247, -0.9743,  0.2045,  0.3812, -0.2564,\n",
      "        -0.0098, -0.3754]))\n",
      "(tensor(6), tensor([-0.3120,  0.0991, -0.0778,  0.1118, -0.4669,  0.0472,  0.3005, -0.1724,\n",
      "        -0.2045, -0.0553]))\n",
      "(tensor(5), tensor([-0.6576,  0.2940, -0.1365, -0.4380, -0.7887,  0.1902,  0.5289, -0.2654,\n",
      "        -0.1796,  0.1167]))\n",
      "(tensor(0), tensor([ 0.1944,  0.1803, -0.3316,  0.6119, -1.3908, -0.1649,  1.2420, -1.0329,\n",
      "         0.7468, -1.1998]))\n"
     ]
    }
   ],
   "source": [
    "for tup in list(zip(TARGET,max(OUTPUT)):\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
